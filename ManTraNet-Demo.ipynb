{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ManTra-Net Demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malsrou/Liveness-Detection/blob/main/ManTraNet-Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mGN6cggOfBYk"
      },
      "cell_type": "markdown",
      "source": [
        "# ManTra-Net: Manipulation Tracing Network For Detection and Localization of Image Forgeries With Anomalous Features\n",
        "\n",
        "## This is a simple demonstrative notebook for the pretrained ManTra-Net\n",
        "\n",
        "## Note:\n",
        "\n",
        "- Please make sure you run this notebook with the GPU support. You may see tensorflow errors when decoding images of very large sizes, e.g. 2048x3072.\n",
        "- All lib/data paths used in this notebook is relative. In case you run this notebook outside of its original location, please fix the data paths."
      ]
    },
    {
      "metadata": {
        "id": "K9-E1qT5fTyn"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Download the ManTraNet Repo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "FILE=ManTraNet/src/modelCore.py\n",
        "\n",
        "# Remove any lines that invoke the legacy interfaces decorator\n",
        "sed -i '/@interfaces\\.legacy_.*_support/d' $FILE\n",
        "\n",
        "echo \"✅ Removed all @interfaces.legacy_*_support decorators. Now restart the runtime and re-run.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XJW0ZXgagyA",
        "outputId": "b34dec50-e4ee-4c14-f037-05b9768bad07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Removed all @interfaces.legacy_*_support decorators. Now restart the runtime and re-run.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "FILE=ManTraNet/src/modelCore.py\n",
        "\n",
        "# 1) Layers\n",
        "sed -i \"s|from keras.layers import Layer, Input, GlobalAveragePooling2D, Lambda, Dense|from tensorflow.keras.layers import Layer, Input, GlobalAveragePooling2D, Lambda, Dense|\" $FILE\n",
        "sed -i \"s|from keras.layers import ConvLSTM2D, Conv2D, AveragePooling2D, BatchNormalization|from tensorflow.keras.layers import ConvLSTM2D, Conv2D, AveragePooling2D, BatchNormalization|\" $FILE\n",
        "\n",
        "# 2) Constraints & initializers\n",
        "sed -i \"s|from keras.constraints import unit_norm, non_neg|from tensorflow.keras.constraints import unit_norm, non_neg|\" $FILE\n",
        "sed -i \"s|from keras.constraints import Constraint|from tensorflow.keras.constraints import Constraint|\" $FILE\n",
        "sed -i \"s|from keras.initializers import Constant|from tensorflow.keras.initializers import Constant|\" $FILE\n",
        "\n",
        "# 3) Activations & backend\n",
        "sed -i \"s|from keras.activations import softmax|from tensorflow.keras.activations import softmax|\" $FILE\n",
        "sed -i \"s|from keras import backend as K|from tensorflow.keras import backend as K|\" $FILE\n",
        "\n",
        "# 4) Model class\n",
        "sed -i \"s|from keras.models import Model|from tensorflow.keras.models import Model|\" $FILE\n",
        "\n",
        "# 5) Conv base class\n",
        "sed -i \"s|from keras.layers.convolutional import _Conv|from tensorflow.keras.layers import Conv2D as _Conv|\" $FILE\n",
        "\n",
        "# 6) Legacy interfaces (comment out)\n",
        "sed -i \"s|from keras.legacy import interfaces|# from keras.legacy import interfaces  # removed legacy TF1.x import|\" $FILE\n",
        "\n",
        "# 7) InputSpec\n",
        "sed -i \"s|from keras.engine import InputSpec|from tensorflow.keras.layers import InputSpec|\" $FILE\n",
        "\n",
        "echo \"✅ Patching done. Now please restart the Colab runtime and re-run your notebook.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JrCZ27iZ0aq",
        "outputId": "3e17fa78-60ec-4a8e-8b71-048ac0a34cde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patching done. Now please restart the Colab runtime and re-run your notebook.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hmvY3irIe3gr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f05f10-9ed6-43e2-cccb-4911a65a4237"
      },
      "cell_type": "code",
      "source": [
        "!rm -rf ManTraNet\n",
        "!git clone https://github.com/ISICV/ManTraNet.git\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ManTraNet'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 211 (delta 29), reused 26 (delta 26), pack-reused 177 (from 1)\u001b[K\n",
            "Receiving objects: 100% (211/211), 140.00 MiB | 22.90 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n",
            "Updating files: 100% (158/158), done.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "yBcO3gXkfexO"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Import Dependent Libs and Set Paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HhpkCeUkYwFu",
        "outputId": "0eba537f-9769-476f-9d91-f41e8b378327"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              },
              "id": "d3b44c33813142229baf0fbd774e9b15"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "XkSm0E62Z9E5"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import requests\n",
        "import sys\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from matplotlib import pyplot\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# if your notebook is in the root and ManTraNet lives in ./ManTraNet\n",
        "sys.path.insert(0, \"ManTraNet/src\")"
      ],
      "metadata": {
        "id": "U_BPV6G7Yqc8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fLLbde5IfvOn"
      },
      "cell_type": "code",
      "source": [
        "manTraNet_root = './ManTraNet/'\n",
        "manTraNet_srcDir = os.path.join( manTraNet_root, 'src' )\n",
        "sys.path.insert( 0, manTraNet_srcDir )\n",
        "manTraNet_modelDir = os.path.join( manTraNet_root, 'pretrained_weights' )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_68Ehftf-Yo"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Load Sample Data"
      ]
    },
    {
      "metadata": {
        "id": "OfG_uW5FgKlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271b2ee2-9352-4f54-e163-195742d37616"
      },
      "cell_type": "code",
      "source": [
        "manTraNet_dataDir = os.path.join( manTraNet_root, 'data' )\n",
        "sample_file = os.path.join( manTraNet_dataDir, 'samplePairs.csv' )\n",
        "assert os.path.isfile( sample_file ), \"ERROR: can NOT find sample data, check `manTraNet_root`\"\n",
        "with open( sample_file ) as IN :\n",
        "    sample_pairs = [line.strip().split(',') for line in IN.readlines() ]\n",
        "L = len(sample_pairs)\n",
        "print(\"INFO: in total, load\", L, \"samples\")\n",
        "\n",
        "def get_a_random_pair() :\n",
        "    idx = np.random.randint(0,L)\n",
        "    return ( os.path.join( manTraNet_dataDir, this ) for this in sample_pairs[idx] )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: in total, load 72 samples\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "q71lTGuugVoy"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Load A Pretrained ManTraNet Model"
      ]
    },
    {
      "metadata": {
        "id": "iFVAQIBmgdr3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "bd43d028-3380-4fdd-f4c3-1e1690695cc4"
      },
      "cell_type": "code",
      "source": [
        "import modelCore\n",
        "manTraNet = modelCore.load_pretrain_model_by_index( 4, manTraNet_modelDir )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "keras.src.layers.convolutional.base_conv.BaseConv.__init__() got multiple values for keyword argument 'rank'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1918069022>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodelCore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmanTraNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelCore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pretrain_model_by_index\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanTraNet_modelDir\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/./ManTraNet/src/modelCore.py\u001b[0m in \u001b[0;36mload_pretrain_model_by_index\u001b[0;34m(pretrain_index, model_dir)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mIMC_model_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_featex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size_list\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpretrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m63\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     \u001b[0msingle_gpu_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mIMC_model_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_featex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size_list\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0mweight_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}/ManTraNet_Ptrain{}.h5\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain_index\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ERROR: fail to locate the pretrained weight file\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./ManTraNet/src/modelCore.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(IMC_model_idx, freeze_featex, window_size_list)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mIMC_model_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_featex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size_list\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0mtype_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIMC_model_idx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mIMC_model_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0mFeatex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_featex_vgg16_base\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtype_idx\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfreeze_featex\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"INFO: freeze feature extraction part, trainable=False\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./ManTraNet/src/modelCore.py\u001b[0m in \u001b[0;36mcreate_featex_vgg16_base\u001b[0;34m(type)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mbname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'b1'\u001b[0m \u001b[0;31m# 32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mnb_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCombinedConv2D\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'c1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimg_input\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2DSymPadding\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnb_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'c2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;31m# block 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./ManTraNet/src/modelCore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, data_format, dilation_rate, activation, padding, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                  \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                  **kwargs):\n\u001b[0;32m--> 125\u001b[0;31m         super(CombinedConv2D, self).__init__(\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./ManTraNet/src/modelCore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, data_format, dilation_rate, activation, padding, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                  \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                  **kwargs):\n\u001b[0;32m---> 43\u001b[0;31m         super(Conv2DSymPadding, self).__init__(\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/conv2d.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     ):\n\u001b[0;32m--> 109\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: keras.src.layers.convolutional.base_conv.BaseConv.__init__() got multiple values for keyword argument 'rank'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HAu-EWn2i3XU"
      },
      "cell_type": "code",
      "source": [
        "# ManTraNet Architecture\n",
        "print(manTraNet.summary(line_length=120))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gz9AfjZljJN8"
      },
      "cell_type": "code",
      "source": [
        "# Image Manipulation Classification Network\n",
        "IMCFeatex = manTraNet.get_layer('Featex')\n",
        "print(IMCFeatex.summary(line_length=120))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Q9xXMAgjvvM"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Play With The Provided Sample Data\n",
        "\n",
        "## Note: we don't need original image files for forgery detection. They are included here to demonstrate the effectiveness of the ManTra-Net.\n"
      ]
    },
    {
      "metadata": {
        "id": "WNRCJeZjjvHm"
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "def read_rgb_image( image_file ) :\n",
        "    rgb = cv2.imread( image_file, 1 )[...,::-1]\n",
        "    return rgb\n",
        "\n",
        "def decode_an_image_array( rgb, manTraNet ) :\n",
        "    x = np.expand_dims( rgb.astype('float32')/255.*2-1, axis=0 )\n",
        "    t0 = datetime.now()\n",
        "    y = manTraNet.predict(x)[0,...,0]\n",
        "    t1 = datetime.now()\n",
        "    return y, t1-t0\n",
        "\n",
        "def decode_an_image_file( image_file, manTraNet ) :\n",
        "    rgb = read_rgb_image( image_file )\n",
        "    mask, ptime = decode_an_image_array( rgb, manTraNet )\n",
        "    return rgb, mask, ptime.total_seconds()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HOoRRthWkG21"
      },
      "cell_type": "code",
      "source": [
        "for k in range(8) :\n",
        "    # get a sample\n",
        "    forged_file, original_file = get_a_random_pair()\n",
        "    # load the original image just for reference\n",
        "    ori = read_rgb_image( original_file )\n",
        "    # manipulation detection using ManTraNet\n",
        "    rgb, mask, ptime = decode_an_image_file( forged_file, manTraNet )\n",
        "    # show results\n",
        "    pyplot.figure( figsize=(15,5) )\n",
        "    pyplot.subplot(131)\n",
        "    pyplot.imshow( ori )\n",
        "    pyplot.title('Original Image')\n",
        "    pyplot.subplot(132)\n",
        "    pyplot.imshow( rgb )\n",
        "    pyplot.title('Forged Image (ManTra-Net Input)')\n",
        "    pyplot.subplot(133)\n",
        "    pyplot.imshow( mask, cmap='gray' )\n",
        "    pyplot.title('Predicted Mask (ManTra-Net Output)')\n",
        "    pyplot.suptitle('Decoded {} of size {} for {:.2f} seconds'.format( os.path.basename( forged_file ), rgb.shape, ptime ) )\n",
        "    pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B7ZmPCrCkp1H"
      },
      "cell_type": "markdown",
      "source": [
        "# 6. Play with Internet Data\n",
        "\n",
        "### Note: Internet images are often compressed and/or resized, and this means subtle manipulations will be much more difficult to detect after such postprocessing.\n",
        "\n",
        "### Therefore, don't be surprised if you see ManTraNet fails on some sample.\n"
      ]
    },
    {
      "metadata": {
        "id": "2bN1n4LLau-M"
      },
      "cell_type": "code",
      "source": [
        "def get_image_from_url(url, xrange=None, yrange=None) :\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img = np.array(img)\n",
        "    if img.shape[-1] > 3 :\n",
        "        img = img[...,:3]\n",
        "    ori = np.array(img)\n",
        "    if xrange is not None :\n",
        "        img = img[:,xrange[0]:xrange[1]]\n",
        "    if yrange is not None :\n",
        "        img = img[yrange[0]:yrange[1]]\n",
        "    mask, ptime =  decode_an_image_array( img, manTraNet )\n",
        "    ptime = ptime.total_seconds()\n",
        "    # show results\n",
        "    if xrange is None and yrange is None :\n",
        "        pyplot.figure( figsize=(15,5) )\n",
        "        pyplot.title('Original Image')\n",
        "        pyplot.subplot(131)\n",
        "        pyplot.imshow( img )\n",
        "        pyplot.title('Forged Image (ManTra-Net Input)')\n",
        "        pyplot.subplot(132)\n",
        "        pyplot.imshow( mask, cmap='gray' )\n",
        "        pyplot.title('Predicted Mask (ManTra-Net Output)')\n",
        "        pyplot.subplot(133)\n",
        "        pyplot.imshow( np.round(np.expand_dims(mask,axis=-1) * img).astype('uint8'), cmap='jet' )\n",
        "        pyplot.title('Highlighted Forged Regions')\n",
        "        pyplot.suptitle('Decoded {} of size {} for {:.2f} seconds'.format( url, rgb.shape, ptime ) )\n",
        "        pyplot.show()\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eBu-fqajvmxi"
      },
      "cell_type": "code",
      "source": [
        "get_image_from_url('https://www.stockvault.net/blog/wp-content/uploads/2015/08/july-2.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GznGCU9vqubG"
      },
      "cell_type": "code",
      "source": [
        " get_image_from_url('https://i.imgur.com/2gS6lgL.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dBMe58uAtuak"
      },
      "cell_type": "code",
      "source": [
        "get_image_from_url('https://www.siliconbeachtraining.co.uk/img/image_1507964385_7e98ab1037f68477c6135f6f8eea280d.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L8me-b8gz8CH"
      },
      "cell_type": "code",
      "source": [
        "get_image_from_url('https://i.kinja-img.com/gawker-media/image/upload/s--SKrtz7en--/c_scale,f_auto,fl_progressive,q_80,w_800/wumjq8ed0k1hfv0smwma.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "npSBzXlrH44x"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}