{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ManTra-Net Demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malsrou/Liveness-Detection/blob/main/ManTraNet-Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mGN6cggOfBYk"
      },
      "cell_type": "markdown",
      "source": [
        "# ManTra-Net: Manipulation Tracing Network For Detection and Localization of Image Forgeries With Anomalous Features\n",
        "\n",
        "## This is a simple demonstrative notebook for the pretrained ManTra-Net\n",
        "\n",
        "## Note:\n",
        "\n",
        "- Please make sure you run this notebook with the GPU support. You may see tensorflow errors when decoding images of very large sizes, e.g. 2048x3072.\n",
        "- All lib/data paths used in this notebook is relative. In case you run this notebook outside of its original location, please fix the data paths."
      ]
    },
    {
      "metadata": {
        "id": "K9-E1qT5fTyn"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Download the ManTraNet Repo"
      ]
    },
    {
      "metadata": {
        "id": "hmvY3irIe3gr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227e16cb-68bc-4b11-b502-053ffb38fa6b"
      },
      "cell_type": "code",
      "source": [
        "!rm -rf ManTraNet\n",
        "!git clone https://github.com/ISICV/ManTraNet.git\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ManTraNet'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 211 (delta 29), reused 26 (delta 26), pack-reused 177 (from 1)\u001b[K\n",
            "Receiving objects: 100% (211/211), 140.00 MiB | 16.93 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n",
            "Updating files: 100% (158/158), done.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "yBcO3gXkfexO"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Import Dependent Libs and Set Paths"
      ]
    },
    {
      "metadata": {
        "id": "XkSm0E62Z9E5"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import requests\n",
        "import sys\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from matplotlib import pyplot\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fLLbde5IfvOn"
      },
      "cell_type": "code",
      "source": [
        "manTraNet_root = './ManTraNet/'\n",
        "manTraNet_srcDir = os.path.join( manTraNet_root, 'src' )\n",
        "sys.path.insert( 0, manTraNet_srcDir )\n",
        "manTraNet_modelDir = os.path.join( manTraNet_root, 'pretrained_weights' )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_68Ehftf-Yo"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Load Sample Data"
      ]
    },
    {
      "metadata": {
        "id": "OfG_uW5FgKlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa9c666-d880-4c4d-deda-683de16958fd"
      },
      "cell_type": "code",
      "source": [
        "manTraNet_dataDir = os.path.join( manTraNet_root, 'data' )\n",
        "sample_file = os.path.join( manTraNet_dataDir, 'samplePairs.csv' )\n",
        "assert os.path.isfile( sample_file ), \"ERROR: can NOT find sample data, check `manTraNet_root`\"\n",
        "with open( sample_file ) as IN :\n",
        "    sample_pairs = [line.strip().split(',') for line in IN.readlines() ]\n",
        "L = len(sample_pairs)\n",
        "print(\"INFO: in total, load\", L, \"samples\")\n",
        "\n",
        "def get_a_random_pair() :\n",
        "    idx = np.random.randint(0,L)\n",
        "    return ( os.path.join( manTraNet_dataDir, this ) for this in sample_pairs[idx] )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: in total, load 72 samples\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "q71lTGuugVoy"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Load A Pretrained ManTraNet Model"
      ]
    },
    {
      "metadata": {
        "id": "iFVAQIBmgdr3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "9d4e1931-d2b2-4ef4-ab15-67473b602db2"
      },
      "cell_type": "code",
      "source": [
        "import modelCore\n",
        "manTraNet = modelCore.load_pretrain_model_by_index( 4, manTraNet_modelDir )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.layers.convolutional'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1918069022>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodelCore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmanTraNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelCore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pretrain_model_by_index\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanTraNet_modelDir\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./ManTraNet/src/modelCore.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_Conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.layers.convolutional'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HAu-EWn2i3XU"
      },
      "cell_type": "code",
      "source": [
        "# ManTraNet Architecture\n",
        "print(manTraNet.summary(line_length=120))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gz9AfjZljJN8"
      },
      "cell_type": "code",
      "source": [
        "# Image Manipulation Classification Network\n",
        "IMCFeatex = manTraNet.get_layer('Featex')\n",
        "print(IMCFeatex.summary(line_length=120))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Q9xXMAgjvvM"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Play With The Provided Sample Data\n",
        "\n",
        "## Note: we don't need original image files for forgery detection. They are included here to demonstrate the effectiveness of the ManTra-Net.\n"
      ]
    },
    {
      "metadata": {
        "id": "WNRCJeZjjvHm"
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "def read_rgb_image( image_file ) :\n",
        "    rgb = cv2.imread( image_file, 1 )[...,::-1]\n",
        "    return rgb\n",
        "\n",
        "def decode_an_image_array( rgb, manTraNet ) :\n",
        "    x = np.expand_dims( rgb.astype('float32')/255.*2-1, axis=0 )\n",
        "    t0 = datetime.now()\n",
        "    y = manTraNet.predict(x)[0,...,0]\n",
        "    t1 = datetime.now()\n",
        "    return y, t1-t0\n",
        "\n",
        "def decode_an_image_file( image_file, manTraNet ) :\n",
        "    rgb = read_rgb_image( image_file )\n",
        "    mask, ptime = decode_an_image_array( rgb, manTraNet )\n",
        "    return rgb, mask, ptime.total_seconds()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HOoRRthWkG21"
      },
      "cell_type": "code",
      "source": [
        "for k in range(8) :\n",
        "    # get a sample\n",
        "    forged_file, original_file = get_a_random_pair()\n",
        "    # load the original image just for reference\n",
        "    ori = read_rgb_image( original_file )\n",
        "    # manipulation detection using ManTraNet\n",
        "    rgb, mask, ptime = decode_an_image_file( forged_file, manTraNet )\n",
        "    # show results\n",
        "    pyplot.figure( figsize=(15,5) )\n",
        "    pyplot.subplot(131)\n",
        "    pyplot.imshow( ori )\n",
        "    pyplot.title('Original Image')\n",
        "    pyplot.subplot(132)\n",
        "    pyplot.imshow( rgb )\n",
        "    pyplot.title('Forged Image (ManTra-Net Input)')\n",
        "    pyplot.subplot(133)\n",
        "    pyplot.imshow( mask, cmap='gray' )\n",
        "    pyplot.title('Predicted Mask (ManTra-Net Output)')\n",
        "    pyplot.suptitle('Decoded {} of size {} for {:.2f} seconds'.format( os.path.basename( forged_file ), rgb.shape, ptime ) )\n",
        "    pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B7ZmPCrCkp1H"
      },
      "cell_type": "markdown",
      "source": [
        "# 6. Play with Internet Data\n",
        "\n",
        "### Note: Internet images are often compressed and/or resized, and this means subtle manipulations will be much more difficult to detect after such postprocessing.\n",
        "\n",
        "### Therefore, don't be surprised if you see ManTraNet fails on some sample.\n"
      ]
    },
    {
      "metadata": {
        "id": "2bN1n4LLau-M"
      },
      "cell_type": "code",
      "source": [
        "def get_image_from_url(url, xrange=None, yrange=None) :\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img = np.array(img)\n",
        "    if img.shape[-1] > 3 :\n",
        "        img = img[...,:3]\n",
        "    ori = np.array(img)\n",
        "    if xrange is not None :\n",
        "        img = img[:,xrange[0]:xrange[1]]\n",
        "    if yrange is not None :\n",
        "        img = img[yrange[0]:yrange[1]]\n",
        "    mask, ptime =  decode_an_image_array( img, manTraNet )\n",
        "    ptime = ptime.total_seconds()\n",
        "    # show results\n",
        "    if xrange is None and yrange is None :\n",
        "        pyplot.figure( figsize=(15,5) )\n",
        "        pyplot.title('Original Image')\n",
        "        pyplot.subplot(131)\n",
        "        pyplot.imshow( img )\n",
        "        pyplot.title('Forged Image (ManTra-Net Input)')\n",
        "        pyplot.subplot(132)\n",
        "        pyplot.imshow( mask, cmap='gray' )\n",
        "        pyplot.title('Predicted Mask (ManTra-Net Output)')\n",
        "        pyplot.subplot(133)\n",
        "        pyplot.imshow( np.round(np.expand_dims(mask,axis=-1) * img).astype('uint8'), cmap='jet' )\n",
        "        pyplot.title('Highlighted Forged Regions')\n",
        "        pyplot.suptitle('Decoded {} of size {} for {:.2f} seconds'.format( url, rgb.shape, ptime ) )\n",
        "        pyplot.show()\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eBu-fqajvmxi"
      },
      "cell_type": "code",
      "source": [
        "get_image_from_url('https://www.stockvault.net/blog/wp-content/uploads/2015/08/july-2.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GznGCU9vqubG"
      },
      "cell_type": "code",
      "source": [
        " get_image_from_url('https://i.imgur.com/2gS6lgL.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dBMe58uAtuak"
      },
      "cell_type": "code",
      "source": [
        "get_image_from_url('https://www.siliconbeachtraining.co.uk/img/image_1507964385_7e98ab1037f68477c6135f6f8eea280d.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L8me-b8gz8CH"
      },
      "cell_type": "code",
      "source": [
        "get_image_from_url('https://i.kinja-img.com/gawker-media/image/upload/s--SKrtz7en--/c_scale,f_auto,fl_progressive,q_80,w_800/wumjq8ed0k1hfv0smwma.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "npSBzXlrH44x"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}